{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNEh3UX7VY9lQgwJU2x0eoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alantang1369/Hurrican_Damage_Detector/blob/main/Hurricane_Damage_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "pqZmz0xcWLus"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/satellitehurricaneimages.zip'\n",
        "urllib.request.urlretrieve(url, 'satellitehurricaneimages.zip')\n",
        "with zipfile.ZipFile('satellitehurricaneimages.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall()"
      ],
      "metadata": {
        "id": "Gzvw__Z2VA3S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 128\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "f_Rpei_cVKlX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image, label):\n",
        "\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "6DOWt6igZVRb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        directory='train/',\n",
        "        image_size=  (IMG_SIZE, IMG_SIZE)\n",
        "        , batch_size=BATCH_SIZE)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        directory='validation/',\n",
        "        image_size=  (IMG_SIZE, IMG_SIZE)\n",
        "        , batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJScPdBsXkwp",
        "outputId": "63c409b7-af0d-46fa-8f37-51068384dc88"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MESHh5zgqsE",
        "outputId": "fc5b5473-406b-4405-f0b7-fbfc750c8c86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizes train and validation datasets using the\n",
        "    # preprocess() function.\n",
        "    # Also makes other calls, as evident from the code, to prepare them for\n",
        "    # training.\n",
        "    # Do not batch or resize the images in the dataset here since it's already\n",
        "    # been done previously.\n",
        "train_ds = train_ds.map(\n",
        "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\n",
        "        tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# train_ds = train_ds.shuffle(buffer_size=1000).batch(batch_size=64).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = val_ds.map(\n",
        "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# val_ds = val_ds.batch(batch_size=64).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "xyRfBMMrZG64"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mjA6r3xChQS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters=10,\n",
        "                         kernel_size=3, # can also be (3, 3)\n",
        "                         activation=\"relu\",\n",
        "                         input_shape=(128, 128, 3)), # first layer specifies input shape (height, width, colour channels)\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n",
        "                            padding=\"valid\"), # padding can also be 'same'\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.Conv2D(10, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n",
        "  tf.keras.layers.MaxPool2D(2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\") # binary activation output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(train_ds,\n",
        "          epochs=10,\n",
        "          steps_per_epoch=len(train_ds),\n",
        "          validation_data=val_ds,\n",
        "          validation_steps=len(val_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCOJgXSHbt6I",
        "outputId": "a2638171-46f3-424f-fe49-73ccf4a461e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 126, 126, 10)      280       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 124, 124, 10)      910       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 62, 62, 10)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 60, 60, 10)        910       \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 58, 58, 10)        910       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 29, 29, 10)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8410)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 8411      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11421 (44.61 KB)\n",
            "Trainable params: 11421 (44.61 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 4s 14ms/step - loss: 0.6156 - accuracy: 0.6051 - val_loss: 0.5301 - val_accuracy: 0.6530\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.4274 - accuracy: 0.8246 - val_loss: 0.3179 - val_accuracy: 0.8775\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.2842 - accuracy: 0.8900 - val_loss: 0.2506 - val_accuracy: 0.9045\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.2340 - accuracy: 0.9060 - val_loss: 0.2017 - val_accuracy: 0.9130\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.1907 - accuracy: 0.9218 - val_loss: 0.1732 - val_accuracy: 0.9510\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.1635 - accuracy: 0.9346 - val_loss: 0.1397 - val_accuracy: 0.9455\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.1494 - accuracy: 0.9407 - val_loss: 0.1429 - val_accuracy: 0.9525\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 2s 13ms/step - loss: 0.1286 - accuracy: 0.9485 - val_loss: 0.1269 - val_accuracy: 0.9525\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.1401 - accuracy: 0.9433 - val_loss: 0.1623 - val_accuracy: 0.9390\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 2s 14ms/step - loss: 0.1189 - accuracy: 0.9554 - val_loss: 0.1275 - val_accuracy: 0.9580\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a630c69b5b0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}